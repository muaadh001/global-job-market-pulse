from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time
import pandas as pd
from fake_useragent import UserAgent

print("✅ Notebook is running")

options = Options()
options.add_argument("--headless")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument(f"user-agent={UserAgent().random}")

driver = webdriver.Chrome(options=options)
driver.get("https://remoteok.com/remote-dev+data-jobs")
time.sleep(3)

rows = driver.find_elements(By.CSS_SELECTOR, "tr.job")
print(f"✅ Found {len(rows)} job rows")

jobs = []
for row in rows:
    try:
        title = row.find_element(By.CSS_SELECTOR, "h2").text
        company = row.find_element(By.CSS_SELECTOR, "h3").text
        location = row.find_element(By.CLASS_NAME, "location").text if row.find_elements(By.CLASS_NAME, "location") else "Remote"
        tags = [tag.text for tag in row.find_elements(By.CLASS_NAME, "tag")]
        link = row.get_attribute("data-href")
        jobs.append({
            "title": title,
            "company": company,
            "location": location,
            "tags": ", ".join(tags),
            "link": f"https://remoteok.com{link}"
        })
    except Exception as e:
        print("⚠️ Skipped a row:", e)

driver.quit()
print(f"✅ Scraped {len(jobs)} jobs")

df = pd.DataFrame(jobs)
df.to_csv("../data/remoteok_jobs.csv", index=False)
print("✅ CSV saved")

